{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edenmoz22/HW2P-Final_Project/blob/main/final_lettersModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hS55VGa5UR2U",
        "outputId": "c87f82da-6c8d-4a5a-8efc-3eeb13f109b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'HW2P-Final_Project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/SitaraAlayev/HW2P-Final_Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCWh6Q-yUUoz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QSyK2IG-5bw0"
      },
      "outputs": [],
      "source": [
        "PATH = '/content/HW2P-Final_Project/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVlSB4zTUXUZ"
      },
      "outputs": [],
      "source": [
        "dir_train = PATH + \"dataset/train/\"\n",
        "dir_test = PATH + \"dataset/test/\"\n",
        "\n",
        "log_dir = PATH + \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atHwDdgHUxVf"
      },
      "outputs": [],
      "source": [
        "def load_images(path, direc, img_size=28):\n",
        "    # load all images from a specific folder and \n",
        "    # returns a X,y set of np.arrays\n",
        "    X = []\n",
        "    for f_name in os.listdir(path+direc):\n",
        "        # define file full path\n",
        "        file_path = path+direc+'/'+f_name\n",
        "        # read and image\n",
        "        img = cv2.imread(file_path, 0)\n",
        "        # append image to X\n",
        "        img = cv2.resize(img,(img_size,img_size))\n",
        "        X.append(img)\n",
        "        \n",
        "\n",
        "    # turn X to np.array\n",
        "    X = np.array(X)\n",
        "    # get a label vector\n",
        "    y = np.array([direc]*X.shape[0])\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "def load_directories(root_dir):\n",
        "    # run over all folders, load X,y (images and labels), and save to a X,y pair for all data\n",
        "    X = None\n",
        "    for direc in os.listdir(root_dir):\n",
        "        X_dir, y_dir = load_images(root_dir, direc)\n",
        "        if X is None:\n",
        "            X = X_dir.copy()\n",
        "            y = y_dir.copy()\n",
        "            continue\n",
        "        X = np.append(X, X_dir, axis=0)\n",
        "        y = np.append(y, y_dir)\n",
        "        # pdb.set_trace()\n",
        "    return X,y\n",
        "\n",
        "# label to letter translation dictionary\n",
        "label_to_letter = {str(i): letter for i, letter in list(enumerate('אבגדהוזחטיכךלמםנןסעפףצץקרשת'))}\n",
        "\n",
        "# load X and y data (Images and Labels)\n",
        "X_train, y_train = load_directories(dir_train)\n",
        "X_test, y_test = load_directories(dir_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg8yn5_RjxqW"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype('float32')/255\n",
        "X_test = X_test.astype('float32')/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5YdjAsYShCO"
      },
      "outputs": [],
      "source": [
        "y_train = tf.keras.utils.to_categorical(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mR5r0uHdgGSE"
      },
      "outputs": [],
      "source": [
        "y_test = tf.keras.utils.to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1qi-zskDwC8"
      },
      "outputs": [],
      "source": [
        "# Create a neural network model\n",
        "def get_model(input_shape = (28,28,1), loss_function='categorical_crossentropy', \n",
        "                optimizer='rmsprop', no_classes=27):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZhf_NOh8rG1"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# Merge inputs and targets\n",
        "inputs = X_train\n",
        "targets = y_train\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "acc_per_fold, loss_per_fold= [], []\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "    # Define the model architecture\n",
        "    model = get_model()\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    n_eval = 20\n",
        "    # Fit data to model\n",
        "    for i in range(n_eval):\n",
        "        history = model.fit(inputs[train], targets[train], batch_size=512, epochs=100//n_eval, verbose=1)\n",
        "        scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "    # Generate generalization metrics\n",
        "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]:.3f}; {model.metrics_names[1]} of {scores[1]*100:.2f}%')\n",
        "    acc_per_fold.append(scores[1] * 100)\n",
        "    loss_per_fold.append(scores[0])\n",
        "    # Increase fold number\n",
        "    fold_no = fold_no + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLc48pOw7bSJ",
        "outputId": "7bb21465-f228-4a0b-bfdd-8d485d75c375"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 [==============================] - 0s 4ms/step - loss: 0.5682 - accuracy: 0.8659\n"
          ]
        }
      ],
      "source": [
        "t_loss, a_acc = model.evaluate(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfTpymjCIUpr"
      },
      "outputs": [],
      "source": [
        "# Saving the model\n",
        "with tf.device('/cpu:0'):\n",
        "    model.save('lettersModel.h5')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "final_lettersModel.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}